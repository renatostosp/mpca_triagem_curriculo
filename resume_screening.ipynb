{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remover .txt e .lab caso o .lab correspondente esteja vazio\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Set the source and destination directories\n",
    "src_dir = 'E:\\\\Renato\\\\desktop-20230306\\\\resumes_corpus'\n",
    "dest_dir = 'E:\\\\Renato\\\\desktop-20230306\\\\empty'\n",
    "\n",
    "# Loop through all the files in the source directory\n",
    "for file in [f for f in os.listdir(src_dir) if f.endswith(\".lab\")]:\n",
    "    src_file = os.path.join(src_dir, file)\n",
    "    dest_file = os.path.join(dest_dir, file)\n",
    "    file_twin = file.split(\".\")[0] + \".txt\"\n",
    "    src_file_twin = os.path.join(src_dir, file_twin)\n",
    "    dest_file_twin = os.path.join(dest_dir, file_twin)\n",
    "\n",
    "    # Check if the file is empty\n",
    "    if os.path.getsize(src_file) == 0:\n",
    "        print(src_file)\n",
    "        shutil.move(src_file, dest_file)\n",
    "        shutil.move(src_file_twin, dest_file_twin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading : 100%|\u001b[31m██████████\u001b[0m| 29035/29035 [07:50<00:00, 61.71it/s]\n",
      "Vazios:  0\n",
      "Loading : 100%|\u001b[31m██████████\u001b[0m| 29035/29035 [02:04<00:00, 233.84it/s]\n",
      "Vazios:  0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import re\n",
    "import unidecode\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from tqdm import tqdm\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "def createDataFrame(path, extension, label, delimiter):\n",
    "    # Create an empty DataFrame\n",
    "    df = pd.DataFrame()\n",
    "    vazios = []\n",
    "\n",
    "    docs_names = os.listdir(path)    \n",
    "    txt_files = [d for d in docs_names if d.endswith(extension)]\n",
    "\n",
    "    with tqdm(total=len(txt_files), file=sys.stdout, colour='red', \\\n",
    "        desc='Loading ') as pbar:\n",
    "\n",
    "        # Loop through all the files in the directory\n",
    "        for filename in os.listdir(path):\n",
    "            if filename.endswith(extension):\n",
    "                # Read the file into a DataFrame\n",
    "                file_path = os.path.join(path, filename)\n",
    "                if delimiter:\n",
    "                    temp_df = pd.read_csv(file_path, delimiter='\\t', encoding = 'ISO-8859-1', header=None)\n",
    "                else:\n",
    "                    temp_df = pd.read_csv(file_path, encoding = 'ISO-8859-1', header=None)\n",
    "                # Add a new column with the filename\n",
    "                temp_df['filename'] = filename.split(sep='.')[0]\n",
    "            \n",
    "                # Append the DataFrame to the main DataFrame\n",
    "                df = pd.concat([df, temp_df])\n",
    "                pbar.update(1)\n",
    "\n",
    "    # Reset the index to start from 0\n",
    "    df = df.reset_index(drop=True)\n",
    "    df = df.rename(columns={0:label})\n",
    "    df['filename']=df['filename'].astype(str)\n",
    "    print(f\"Vazios:  {len(vazios)}\")\n",
    "    return df\n",
    "\n",
    "def preprocessing(txt):\n",
    "    texts_pre = []\n",
    "    texts_preprocessed = []\n",
    "    spacy_stopwords = nlp.Defaults.stop_words\n",
    "    stemmer = PorterStemmer()\n",
    "    # convert all characters in the string to lower case\n",
    "    txt = txt.lower()\n",
    "    # remove non-english characters, punctuation and numbers\n",
    "    txt = re.sub('[^a-zA-Z0-9]', ' ', txt) #\n",
    "    txt = re.sub('http\\S+\\s*', ' ', txt)  # remove URLs\n",
    "    txt = re.sub('RT|cc', ' ', txt)  # remove RT and cc\n",
    "    txt = re.sub('#\\S+', '', txt)  # remove hashtags\n",
    "    txt = re.sub('@\\S+', '  ', txt)  # remove mentions\n",
    "    txt = re.sub('\\s+', ' ', txt)  # remove extra whitespace\n",
    "    txt = txt.replace('\\n', ' ')\n",
    "    txt = unidecode.unidecode(txt)\n",
    "    doc = nlp(txt)\n",
    "    tokens = [t.text.lower() for t in doc]\n",
    "    text = ' '.join(tokens) \n",
    "    text_without_stopword = [word for word in text.split() if word not in spacy_stopwords]\n",
    "    txt_final = [stemmer.stem(w) for w in text_without_stopword]\n",
    "    return txt_final\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    path = 'E:\\\\Renato\\\\desktop-20230306\\\\resumes_corpus'\n",
    "    extension = \".txt\"\n",
    "    label = 'resume'\n",
    "    extension_2 = \".lab\"\n",
    "    label_2 = 'label'\n",
    "    df = createDataFrame(path, extension, label, delimiter=True)\n",
    "    df2 = createDataFrame(path, extension_2, label_2, delimiter=False)\n",
    "    df2 = df2.groupby('filename').agg(lambda x: ' '.join(map(str, x))).reset_index()\n",
    "    df2['label'] = df2['label'].str.split().str[0]\n",
    "    df3 = df.merge(df2, on='filename', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 29035 entries, 0 to 29034\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   resume    29035 non-null  object\n",
      " 1   filename  29035 non-null  object\n",
      " 2   label     29035 non-null  object\n",
      "dtypes: object(3)\n",
      "memory usage: 907.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df3.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resume</th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "      <th>Resume_nlp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Database Administrator &lt;span class=\"hl\"&gt;Databa...</td>\n",
       "      <td>00001</td>\n",
       "      <td>Database_Administrator</td>\n",
       "      <td>['databas', 'administr', 'span', 'class', 'hl'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Database Administrator &lt;span class=\"hl\"&gt;Databa...</td>\n",
       "      <td>00002</td>\n",
       "      <td>Database_Administrator</td>\n",
       "      <td>['databas', 'administr', 'span', 'class', 'hl'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Oracle Database Administrator Oracle &lt;span cla...</td>\n",
       "      <td>00003</td>\n",
       "      <td>Database_Administrator</td>\n",
       "      <td>['oracl', 'databas', 'administr', 'oracl', 'sp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Amazon Redshift Administrator and ETL Develope...</td>\n",
       "      <td>00004</td>\n",
       "      <td>Database_Administrator</td>\n",
       "      <td>['amazon', 'redshift', 'administr', 'etl', 'de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Scrum Master Scrum Master Scrum Master Richmon...</td>\n",
       "      <td>00005</td>\n",
       "      <td>Database_Administrator</td>\n",
       "      <td>['scrum', 'master', 'scrum', 'master', 'scrum'...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              resume filename  \\\n",
       "0  Database Administrator <span class=\"hl\">Databa...    00001   \n",
       "1  Database Administrator <span class=\"hl\">Databa...    00002   \n",
       "2  Oracle Database Administrator Oracle <span cla...    00003   \n",
       "3  Amazon Redshift Administrator and ETL Develope...    00004   \n",
       "4  Scrum Master Scrum Master Scrum Master Richmon...    00005   \n",
       "\n",
       "                    label                                         Resume_nlp  \n",
       "0  Database_Administrator  ['databas', 'administr', 'span', 'class', 'hl'...  \n",
       "1  Database_Administrator  ['databas', 'administr', 'span', 'class', 'hl'...  \n",
       "2  Database_Administrator  ['oracl', 'databas', 'administr', 'oracl', 'sp...  \n",
       "3  Database_Administrator  ['amazon', 'redshift', 'administr', 'etl', 'de...  \n",
       "4  Database_Administrator  ['scrum', 'master', 'scrum', 'master', 'scrum'...  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Software_Developer        5828\n",
       "Systems_Administrator     4182\n",
       "Project_manager           3527\n",
       "Web_Developer             3466\n",
       "Database_Administrator    2784\n",
       "Java_Developer            2418\n",
       "Python_Developer          2311\n",
       "Network_Administrator     2260\n",
       "Security_Analyst          2259\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Renato\\AppData\\Local\\Temp\\ipykernel_8968\\1162965336.py:10: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  result_df = result_df.append(temp_df, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "# get unique values of column A\n",
    "unique_values = df3['label'].unique()\n",
    "\n",
    "# create an empty dataframe to store the results\n",
    "result_df = pd.DataFrame(columns=df3.columns)\n",
    "\n",
    "# loop through the unique values and append 500 rows to the result dataframe for each value\n",
    "for value in unique_values:\n",
    "    temp_df = df3[df3['label'] == value].iloc[:500]\n",
    "    result_df = result_df.append(temp_df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Database_Administrator    500\n",
       "Systems_Administrator     500\n",
       "Project_manager           500\n",
       "Software_Developer        500\n",
       "Web_Developer             500\n",
       "Security_Analyst          500\n",
       "Network_Administrator     500\n",
       "Java_Developer            500\n",
       "Python_Developer          500\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df['Resume_nlp'] = result_df['resume'].apply(lambda w: preprocessing(w)).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training Score: 0.84\n",
      "test Score: 0.71\n",
      "model report: RandomForestClassifier(max_depth=8, n_estimators=500, random_state=42): \n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "Database_Administrator       0.84      0.66      0.74       101\n",
      "        Java_Developer       0.91      0.93      0.92        90\n",
      " Network_Administrator       0.56      0.77      0.65        92\n",
      "       Project_manager       0.66      0.73      0.69       117\n",
      "      Python_Developer       0.99      0.90      0.94       106\n",
      "      Security_Analyst       0.78      0.75      0.77       106\n",
      "    Software_Developer       0.77      0.33      0.46       101\n",
      " Systems_Administrator       0.61      0.47      0.53        98\n",
      "         Web_Developer       0.51      0.89      0.64        89\n",
      "\n",
      "              accuracy                           0.71       900\n",
      "             macro avg       0.74      0.71      0.71       900\n",
      "          weighted avg       0.74      0.71      0.71       900\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Balancear somente o conjunto de treinamento'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vectorize text data\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,1), max_features=None)\n",
    "X_vect = vectorizer.fit_transform(result_df['Resume_nlp']).toarray()\n",
    "#conuntvectorizer_test = vectorizer.transform(X_test).astype(float)\n",
    "\n",
    "new_df = pd.DataFrame(X_vect, columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(new_df, result_df['label'], test_size = 0.2)\n",
    "\n",
    "\"\"\"# **Random Forest Classifier**\"\"\"\n",
    "\n",
    "RF_Model = RandomForestClassifier(random_state=42, n_estimators= 500, max_depth=8, criterion='gini')\n",
    "RF_Model.fit(X_train, Y_train)\n",
    "\n",
    "prediction=RF_Model.predict(X_test)\n",
    "prediction\n",
    "\n",
    "print(\"training Score: {:.2f}\".format(RF_Model.score(X_train, Y_train)))\n",
    "print(\"test Score: {:.2f}\".format(RF_Model.score(X_test, Y_test)))\n",
    "\n",
    "print(\"model report: %s: \\n %s\\n\" % (RF_Model, metrics.classification_report(Y_test, prediction)))\n",
    "\n",
    "\"\"\"Balancear somente o conjunto de treinamento\"\"\"\n",
    "\n",
    "Hilário Tomaz\n",
    "19:28\n",
    "hilariooliveira"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
